# VeriSelect-Automated-Post-Selection-Document-Verification-Portal

## Code:
```py
# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HWeFbsCDZ2C1vKY7QurtPJL3OjGYjWCe
"""

!apt-get install -y poppler-utils tesseract-ocr
!pip install pdf2image pytesseract PyPDF2 opencv-python pillow

import os, zipfile
from PyPDF2 import PdfReader
from pdf2image import convert_from_path
from PIL import Image
import cv2, numpy as np, pytesseract, re, json

zip_path = "//content/zip file.zip"
extract_dir = "/content/extracted_pdfs"
ocr_output_dir = "/content/ocr_texts"
json_dir = "/content/json_output"


for d in (extract_dir, ocr_output_dir, json_dir):
    os.makedirs(d, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    for file in zip_ref.namelist():
        if file.lower().endswith('.pdf'):
            zip_ref.extract(file, extract_dir)

print("Extracted PDF files:")
for f in os.listdir(extract_dir):
    print(f)

def preprocess_image(pil_img):
    img = np.array(pil_img)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    img = cv2.medianBlur(img, 3)
    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                cv2.THRESH_BINARY, 31, 2)
    return Image.fromarray(img)

def ocr_pdf(pdf_path):
    """Extract text from PDF, use PDF text if available else Tesseract OCR."""
    text = ""
    try:
        reader = PdfReader(pdf_path)
        for p in reader.pages:
            t = p.extract_text()
            if t:
                text += "\n" + t
        if text.strip():
            return text
    except Exception:
        pass  # fall back to OCR if text layer fails

    pages = convert_from_path(pdf_path, dpi=400)
    for i, page in enumerate(pages):
        proc = preprocess_image(page)
        txt = pytesseract.image_to_string(proc, lang='eng', config='--oem 3 --psm 6')
        text += f"\n---- PAGE {i+1} ----\n{txt}"
    return text

for pdf_file in os.listdir(extract_dir):
    if not pdf_file.lower().endswith(".pdf"):
        continue
    pdf_path = os.path.join(extract_dir, pdf_file)
    txt_path = os.path.join(ocr_output_dir, pdf_file.replace(".pdf", ".txt"))
    print(f"Processing {pdf_file} ...")
    text = ocr_pdf(pdf_path)
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(text)
    print(" → OCR complete:", txt_path)

print("\n✅ All PDFs processed. Text files saved in:", ocr_output_dir)

import re, os, json

ocr_dir = "/content/ocr_texts"
json_dir = "/content/json_output"
os.makedirs(json_dir, exist_ok=True)

# === Aadhaar ===
def extract_aadhaar_fields(text):
    data = {}
    name_match = re.search(r"(?i)name[:\s]+([A-Z][A-Za-z\s]+)", text)
    aadhaar_match = re.search(r"\b\d{4}\s\d{4}\s\d{4}\b", text)
    dob_match = re.search(r"(?i)(dob|date of birth)[:\s]+(\d{2}[-/]\d{2}[-/]\d{4})", text)
    gender_match = re.search(r"(?i)\b(Male|Female|Transgender|M|F|T)\b", text)

    if name_match: data["Name"] = name_match.group(1).strip()
    if aadhaar_match: data["Aadhaar_Number"] = aadhaar_match.group(0).strip()
    if dob_match: data["DOB"] = dob_match.group(2).strip()
    if gender_match: data["Gender"] = gender_match.group(1).strip().capitalize()
    return data

# === PAN Card ===
def extract_pan_fields(text):
    data = {}
    pan_match = re.search(r"[A-Z]{5}\d{4}[A-Z]", text)
    name_match = re.search(r"(?i)name[:\s]+([A-Z][A-Za-z\s]+)", text)
    father_match = re.search(r"(?i)father[:'\s]+([A-Z][A-Za-z\s]+)", text)
    dob_match = re.search(r"(?i)(dob|date of birth)[:\s]+(\d{2}[-/]\d{2}[-/]\d{4})", text)

    if name_match: data["Name"] = name_match.group(1).strip()
    if pan_match: data["PAN_Number"] = pan_match.group(0).strip()
    if father_match: data["Father_Name"] = father_match.group(1).strip()
    if dob_match: data["DOB"] = dob_match.group(2).strip()
    return data

# === Passport ===
def extract_passport_fields(text):
    data = {}
    name_match = re.search(r"(?i)(name|surname)[:\s]+([A-Z][A-Za-z\s]+)", text)
    pass_no_match = re.search(r"[A-Z]\d{7}", text)
    dob_match = re.search(r"(?i)(dob|date of birth)[:\s]+(\d{2}[-/]\d{2}[-/]\d{4})", text)
    nationality_match = re.search(r"(?i)(nationality)[:\s]+([A-Za-z]+)", text)
    issue_match = re.search(r"(?i)(date of issue)[:\s]+(\d{2}[-/]\d{2}[-/]\d{4})", text)
    expiry_match = re.search(r"(?i)(date of expiry)[:\s]+(\d{2}[-/]\d{2}[-/]\d{4})", text)

    if name_match: data["Name"] = name_match.group(2).strip()
    if pass_no_match: data["Passport_Number"] = pass_no_match.group(0).strip()
    if dob_match: data["DOB"] = dob_match.group(2).strip()
    if nationality_match: data["Nationality"] = nationality_match.group(2).strip()
    if issue_match: data["Issue_Date"] = issue_match.group(2).strip()
    if expiry_match: data["Expiry_Date"] = expiry_match.group(2).strip()
    return data

# === 10th / 12th Certificates ===
def extract_marks_fields(text, ignore_last_n=0):
    data = {}
    name_match = re.search(r"(?i)name[:\s]+([A-Z][A-Za-z\s]+)", text)
    dob_match = re.search(r"(?i)(dob|date of birth)[:\s]+([\d]{2}[-/][\d]{2}[-/][\d]{4})", text)
    roll_match = re.search(r"(?i)(roll\s?no|register\s?number)[:\s]+([A-Za-z0-9]+)", text)
    school_match = re.search(r"(?i)(school\s?name|institution)[:\s]+([A-Z0-9][A-Za-z0-9\s,]+)", text)
    board_match = re.search(r"(?i)(board|education\s?board)[:\s]+([A-Z\s]+)", text)

    if name_match: data["Name"] = name_match.group(1).strip()
    if dob_match: data["DOB"] = dob_match.group(2).strip()
    if roll_match: data["Roll_Number"] = roll_match.group(2).strip()
    if school_match: data["School_Name"] = school_match.group(2).strip()
    elif board_match: data["Board_Name"] = board_match.group(2).strip()

    subjects = []
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    subj_pattern = re.compile(r"([A-Za-z\s]+)\s+(\d{1,3})")

    for line in lines:
        m = subj_pattern.search(line)
        if m:
            subj = m.group(1).strip()
            mark = int(m.group(2))
            subjects.append({"Subject": subj, "Marks": mark})

    if ignore_last_n and len(subjects) > ignore_last_n:
        subjects = subjects[:-ignore_last_n]

    data["Subjects"] = subjects
    return data

# === College / Degree Certificates ===
def extract_college_certificate(text):
    data = {}
    name_match = re.search(r"(?i)(this is to certify that|awarded to)\s+([A-Z][A-Za-z\s]+)", text)
    college_match = re.search(r"(?i)(college|university)\s+of\s+([A-Z][A-Za-z\s]+)", text)
    degree_match = re.search(r"(?i)(degree|bachelor|master)\s+of\s+([A-Z][A-Za-z\s]+)", text)
    year_match = re.search(r"(?i)(year\s*of\s*passing|completed\s*in)\s*(\d{4})", text)
    branch_match = re.search(r"(?i)(branch|specialization|discipline)\s*[:\-]?\s*([A-Z][A-Za-z\s]+)", text)

    if name_match: data["Name"] = name_match.group(2).strip()
    if college_match: data["College_Name"] = "University of " + college_match.group(2).strip()
    if degree_match: data["Degree"] = "Bachelor of " + degree_match.group(2).strip()
    if branch_match: data["Branch"] = branch_match.group(2).strip()
    if year_match: data["Year_of_Passing"] = year_match.group(2).strip()
    return data

# === Main Conversion Loop ===
for file in os.listdir(ocr_dir):
    if not file.endswith(".txt"):
        continue

    text = open(os.path.join(ocr_dir, file), "r", encoding="utf-8").read()
    fname = file.lower()

    if "aadhaar" in fname:
        result = extract_aadhaar_fields(text)
    elif "pan" in fname:
        result = extract_pan_fields(text)
    elif "passport" in fname:
        result = extract_passport_fields(text)
    elif "12" in fname or "hsc" in fname:
        result = extract_marks_fields(text, ignore_last_n=3)
    elif "10" in fname or "sslc" in fname:
        result = extract_marks_fields(text, ignore_last_n=1)
    elif "degree" in fname or "college" in fname:
        result = extract_college_certificate(text)
    else:
        result = {"RawText": text[:400]}

    out_path = os.path.join(json_dir, file.replace(".txt", ".json"))
    with open(out_path, "w", encoding="utf-8") as jf:
        json.dump(result, jf, indent=4, ensure_ascii=False)

    print(f"Converted: {file} → {out_path}")

print("\n✅ All OCR text files converted to structured JSON in:", json_dir)
````
```py

{
  "photo_url": "https://storage.example.com/photos/sreevalsan.jpg",

  "identity_verification": {
    "aadhaar": {
      "verified": true,
      "reason": "Matched with UIDAI data"
    },
    "pan": {
      "verified": false,
      "reason": "Name mismatch with Aadhaar"
    },
    "passport": {
      "verified": true,
      "reason": "All details consistent"
    },
    "summary": {
      "overall_identity_verified": false,
      "reason": "PAN verification failed"
    }
  },

  "education_verification": {
    "tenth_certificate": {
      "verified": true,
      "reason": "Matched with board record"
    },
    "twelfth_certificate": {
      "verified": true,
      "reason": "All subjects consistent"
    },
    "degree_certificate": {
      "verified": false,
      "reason": "University record not found in DigiLocker"
    },
    "summary": {
      "overall_education_verified": false,
      "reason": "Degree not verified"
    }
  },

  "certifications_verification": {
    "coursera_certificate": {
      "verified": true,
      "reason": "Verified via Coursera public API"
    },
    "udemy_certificate": {
      "verified": false,
      "reason": "Certificate ID invalid or revoked"
    },
    "summary": {
      "overall_certification_verified": false,
      "reason": "One invalid certificate found"
    }
  },

  "employment_verification": {
    "previous_company": {
      "company_name": "TechNova Systems",
      "hr_contact_email": "hr@technova.in",
      "hr_contact_number": "+91-9876543210",
      "verified": true,
      "reason": "Confirmed by HR via API"
    },
    "summary": {
      "overall_employment_verified": true
    }
  },

  "final_verification_summary": {
    "overall_verified": false,
    "failed_segments": [
      "Identity (PAN)",
      "Education (Degree)",
      "Certifications (Udemy)"
    ],
    "remarks": "Candidate verified except for degree and PAN mismatch"
  }
}
